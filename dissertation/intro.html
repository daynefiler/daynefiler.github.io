<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction | Tools and statistical approaches for integrating DNA sequencing into clinical care</title>
  <meta name="description" content="Dissertation by Dayne Filer for the degree of Doctorate of Philosophy in the UNC School of Medicine Curriculum in Bioinformatics and Computational Biology." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction | Tools and statistical approaches for integrating DNA sequencing into clinical care" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Dissertation by Dayne Filer for the degree of Doctorate of Philosophy in the UNC School of Medicine Curriculum in Bioinformatics and Computational Biology." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction | Tools and statistical approaches for integrating DNA sequencing into clinical care" />
  
  <meta name="twitter:description" content="Dissertation by Dayne Filer for the degree of Doctorate of Philosophy in the UNC School of Medicine Curriculum in Bioinformatics and Computational Biology." />
  

<meta name="author" content="Dayne Lewis Filer" />


<meta name="date" content="2020-01-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="a-novel-copy-number-variant-algorithm.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<link rel="stylesheet" href="style/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Front matter</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#copyright"><i class="fa fa-check"></i>Copyright</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#preface"><i class="fa fa-check"></i>Preface</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#outline"><i class="fa fa-check"></i><b>1.1</b> Outline</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#human-genetics-primer"><i class="fa fa-check"></i><b>1.2</b> Human genetics primer</a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#discovery-of-dna-and-the-central-dogma"><i class="fa fa-check"></i><b>1.2.1</b> Discovery of DNA and the central dogma</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#genetic-variation-in-humans"><i class="fa fa-check"></i><b>1.2.2</b> Genetic variation in humans</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#dna-sequencing"><i class="fa fa-check"></i><b>1.3</b> DNA Sequencing</a><ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#first-generation-sequencing"><i class="fa fa-check"></i><b>1.3.1</b> First-generation sequencing</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#second-generation-sequencing"><i class="fa fa-check"></i><b>1.3.2</b> Second-generation sequencing</a></li>
<li class="chapter" data-level="1.3.3" data-path="intro.html"><a href="intro.html#processing-short-read-sequencing-data"><i class="fa fa-check"></i><b>1.3.3</b> Processing short-read sequencing data</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#introduction-to-medical-genetics"><i class="fa fa-check"></i><b>1.4</b> Introduction to medical genetics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html"><i class="fa fa-check"></i><b>2</b> A novel copy number variant algorithm</a><ul>
<li class="chapter" data-level="2.1" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#methods"><i class="fa fa-check"></i><b>2.2</b> Methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#exome-sequencing"><i class="fa fa-check"></i><b>2.2.1</b> Exome sequencing</a></li>
<li class="chapter" data-level="2.2.2" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#genome-sequencing"><i class="fa fa-check"></i><b>2.2.2</b> Genome sequencing</a></li>
<li class="chapter" data-level="2.2.3" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#simulating-targeted-sequencing"><i class="fa fa-check"></i><b>2.2.3</b> Simulating targeted sequencing</a></li>
<li class="chapter" data-level="2.2.4" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#mccnv-algorithm"><i class="fa fa-check"></i><b>2.2.4</b> mcCNV algorithm</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#results"><i class="fa fa-check"></i><b>2.3</b> Results</a><ul>
<li class="chapter" data-level="2.3.1" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#multiplexed-capture-reduces-inter-sample-variance"><i class="fa fa-check"></i><b>2.3.1</b> Multiplexed capture reduces inter-sample variance</a></li>
<li class="chapter" data-level="2.3.2" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#multiplexed-capture-provides-controls-for-exomedepth"><i class="fa fa-check"></i><b>2.3.2</b> Multiplexed capture provides controls for ExomeDepth</a></li>
<li class="chapter" data-level="2.3.3" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#mccnv-exomedepth-perform-comparably-in-simulation-study"><i class="fa fa-check"></i><b>2.3.3</b> mcCNV &amp; ExomeDepth perform comparably in simulation study</a></li>
<li class="chapter" data-level="2.3.4" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#mccnv-exomedepth-perform-comparably-on-wgs-pool"><i class="fa fa-check"></i><b>2.3.4</b> mcCNV &amp; ExomeDepth perform comparably on WGS pool</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="a-novel-copy-number-variant-algorithm.html"><a href="a-novel-copy-number-variant-algorithm.html#discussion"><i class="fa fa-check"></i><b>2.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><i class="fa fa-check"></i><b>3</b> Shortcomings of exome sequencing in noninvasive prenatal genetics</a><ul>
<li class="chapter" data-level="3.1" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#methods-1"><i class="fa fa-check"></i><b>3.2</b> Methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#participant-selection"><i class="fa fa-check"></i><b>3.2.1</b> Participant selection</a></li>
<li class="chapter" data-level="3.2.2" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#exome-sequencing-and-analysis"><i class="fa fa-check"></i><b>3.2.2</b> Exome sequencing and analysis</a></li>
<li class="chapter" data-level="3.2.3" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#genotyping-algorithm"><i class="fa fa-check"></i><b>3.2.3</b> Genotyping algorithm</a></li>
<li class="chapter" data-level="3.2.4" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#data-availability"><i class="fa fa-check"></i><b>3.2.4</b> Data availability</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#results-1"><i class="fa fa-check"></i><b>3.3</b> Results</a></li>
<li class="chapter" data-level="3.4" data-path="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html"><a href="shortcomings-of-exome-sequencing-in-noninvasive-prenatal-genetics.html#discussion-1"><i class="fa fa-check"></i><b>3.4</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Tools and statistical approaches for integrating DNA sequencing into clinical care</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<div id="outline" class="section level2">
<h2><span class="header-section-number">1.1</span> Outline</h2>
</div>
<div id="human-genetics-primer" class="section level2">
<h2><span class="header-section-number">1.2</span> Human genetics primer</h2>
<div id="discovery-of-dna-and-the-central-dogma" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Discovery of DNA and the central dogma</h3>
<p>The discovery of deoxyribonucleic acid (DNA) took roughly 100 years of work, and has fundamentally changed how we view ourselves, society, and life.
The study of genetics begins with the study of peas and the discovery of inheritance by Gregor Mendel in the middle of the 19th century.<span class="citation"><sup><a href="references.html#ref-mendel:1866aa" role="doc-biblioref">1</a></sup></span>
Shortly after Mendel’s work, Friedrich Miescher isolated “nuclein” from lymphocytes noting the uniquenely high proportion of phosphorus in the form of phosphoric acid.<span class="citation"><sup><a href="references.html#ref-miescher:1871aa" role="doc-biblioref">2</a>–<a href="references.html#ref-miescher:1874ab" role="doc-biblioref">4</a></sup></span>
Albrecht Kossel and Albert Neumann furthered Miescher’s work by identifying the four bases and renaming “nuclein” deoxyribonucleic acid.<span class="citation"><sup><a href="references.html#ref-kossel:1893aa" role="doc-biblioref">5</a></sup></span>
Walther Flemming first described mitosis (the division of cells) showing the doubling and separation of chromosomes.<span class="citation"><sup><a href="references.html#ref-flemming:1878aa" role="doc-biblioref">6</a></sup></span>
Theodor Boveri and Walter Sutton independently discovered meiosis, establishing chromosomes as the vehicle for inheritance (i.e. the “chromosome theory of inheritance”).<span class="citation"><sup><a href="references.html#ref-boveri:1902aa" role="doc-biblioref">7</a>–<a href="references.html#ref-sutton:1903aa" role="doc-biblioref">9</a></sup></span></p>
<p>Despite early suggestions of chromatin containing DNA by Kossel and Neumann, many believed proteins and not DNA coded the fundamental information for inheritance.
Oswald Avery, Collin MacLeod, and Maclyn McCarty published the first experiments to establish DNA carries the hedidary code using <em>Diplococcus pneumoniae</em>.<span class="citation"><sup><a href="references.html#ref-avery:1944aa" role="doc-biblioref">10</a></sup></span>
Erwin Chargaff rightly believed the work by Avery <em>et al.</em> and went on to discover equal proportions of adenine/thymine guanine/cytosine (“Chargaff’s rule”) which disproved the tetranucleotide hypothesis and laid the groundwork for the double helical model.<span class="citation"><sup><a href="references.html#ref-chargaff:1949aa" role="doc-biblioref">11</a></sup></span>
In the early 1950’s Roslind Franklin started using X-ray crystallography to study the structure of DNA, producing the first images showing the double helical form.<span class="citation"><sup><a href="references.html#ref-franklin:1953aa" role="doc-biblioref">12</a></sup></span>
Watson and Crick were given Rosalind’s images without her knowledge or permission, allowing them to perform the final work to establish the structure of DNA.<span class="citation"><sup><a href="references.html#ref-watson:1953aa" role="doc-biblioref">13</a></sup></span>
Crick went on to establish the Central Dogma of Molecular Biology.<span class="citation"><sup><a href="references.html#ref-crick:1958aa" role="doc-biblioref">14</a>,<a href="references.html#ref-crick:1970aa" role="doc-biblioref">15</a></sup></span></p>
<p>The Central Dogma of Molecular Biology describes the process by which DNA codes for the proteins that build and sustain eukaryotic life.
To produce proteins, ribonucleic acid (RNA) polymerase first transcribes the DNA message into single-stranded RNA molecules (messanger RNA, mRNA).
The mRNA, after post-transcriptional modifications including possible splicing (reorganization), is then translated into a polymer of amino acids by ribosomal RNA complexes.
Amino acid polymers, also known as polypeptides or peptide chains, form the primary structure of proteins.
Therefore, modifications to DNA have profound impacts on cellular and organismal function.</p>
</div>
<div id="genetic-variation-in-humans" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Genetic variation in humans</h3>
<p>Humans are diploid organisms, meaning we have two copies of each chromosome.
Under normal circumstances, we receive one set of chromosomes each from our biological mother and father.
Humans have 46 chromosomes (23 from each parent), including 21 autosomes (chromosomes 1-22) and two sex chromosomes (X and Y).<span class="citation"><sup><a href="references.html#ref-tjio:1956aa" role="doc-biblioref">16</a></sup></span>
The haploid (single copy) genome spans roughly 3.1 billion basepairs, of which roughly 1.5% is predicted to code for protein.<span class="citation"><sup><a href="references.html#ref-lander:2001aa" role="doc-biblioref">17</a></sup></span>
Broadly, four classes of variants occur within DNA: (1) single nucleotide substitutions (single nucleotide variants, SNVs), (2) insertions and deletions (indels), (3) copy number variants, and (4) translocations and inversions.</p>
<p>SNVs occur when one base replaces another in a specific sequence.
DNA codes for amino acids (the building blocks for protein) using three consecutive bases (a codon).
The codon code includes redundancy in the third position (e.g. the sequences GAA and GAG both code for the amino acid glutamic acid).
Consequently, synonymous and non-synonymous mutations exist.
Synonymous mutations occur in the third position of the codon and do not change the resulting amino acid.
Non-synonymous mutations change the resulting protein structure, either by an amino acid substitution (missense mutations), causing a premature stop codon (nonsense mutation), eliminating a start codon (nonstart mutation), or eliminating the stop codon (nonstop mutation).
SNVs can occur through polymerase errors during DNA replication and mutagenic substances (e.g. specifc wavelengths of light, chemical exposure).</p>
<p>The remaining three types of mutations fall into the large category of structural variation (SV), with muddy lines between what constitutes an insertion/deletion (indel) versus copy number variant (CNV).
Indels represent small insertions of deletions of genetic material; any indel with length not divisible by three can cause a frameshift mutation, where the genetic reading frame gets shifted and all subsequent amino acids translate incorrectly.
Copy number variants represent larger insertions or deletions and can range from a single exon up to whole chromosomes (aneuploidy).
Aneuploidy occurs due to mitotic segregation errors during cellular replication.
Smaller copy number variation likely occurs through non-allelic homologous recombination (NAHR), non-homologous end-joining (NHEJ), fork stalling and template switching (FoSTeS), and retrotransposition.<span class="citation"><sup><a href="references.html#ref-gu:2008aa" role="doc-biblioref">18</a></sup></span></p>
<p>We call segmental rearrangements a translocation when the segment moves from one locus to another, and an inversion when the segment gets flipped and reinserted.
Rearrangements can cause detrimental effects when they disrupt gene sequence.
The same processes creating CNVs discussed above can create rearrangments, and rearrangments often go hand-in-hand with copy number variation.</p>
</div>
</div>
<div id="dna-sequencing" class="section level2">
<h2><span class="header-section-number">1.3</span> DNA Sequencing</h2>
<div id="first-generation-sequencing" class="section level3">
<h3><span class="header-section-number">1.3.1</span> First-generation sequencing</h3>
<p>Using lessons learned from previous RNA sequencing efforts, the first DNA sequencing techniques arose in the 1970s with Sanger’s original plus-minus approach,<span class="citation"><sup><a href="references.html#ref-sanger:1975aa" role="doc-biblioref">19</a></sup></span> the Maxam-Gilbert chemical cleavage approach,<span class="citation"><sup><a href="references.html#ref-maxam:1977aa" role="doc-biblioref">20</a></sup></span> and Sanger’s chain termination approach.<span class="citation"><sup><a href="references.html#ref-sanger:1977aa" role="doc-biblioref">21</a></sup></span></p>
<p>Maxam-Gilbert sequencing works by cleaving DNA sequences at specific base pairs using specific chemical reactions.
Before cleaving, radioactive phosphorus is incorporated into the 5 prime terminus of the DNA fragment to be sequenced.
The fragment is then cleaved randomly in four separate reactions: at either G, G and A, C, or C and T.
The cleaved radio-labeled fragments from each of the four reactions are then size-separated and visualized on a polyacrylamide gel.</p>
<p>Sanger sequencing (chain termination) was the first sequencing by synthesis (SBS) approach.
Similar to Maxam-Gilbert sequencing, the target DNA fragment is replicated by the polymerase chain reaction (PCR) in four separate conditions.
Each condition contains an equimolar mix of the four deoxynucleotide triphosphate (dNTP, DNA bases) molecules and a small amount of a single radio- or fluorescently-labeled dideoxynucleotide (ddNTP).
The PCR reaction cannot proceed after the incorporation of a ddNTP, so each of the four reactions will contain synthesized fragments that stop at the same base.
Again, the four reactions are size-separated and visualized on a polyacrylamide gel.</p>
</div>
<div id="second-generation-sequencing" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Second-generation sequencing</h3>
<p>In the following decade Nyrèn and Lundin discovered an enzymatic method for detecting the incorporation of a new base during sequencing.<span class="citation"><sup><a href="references.html#ref-nyren:1985aa" role="doc-biblioref">22</a></sup></span>
Pyrophosphate is released when dNTPs are incorporated into a DNA polymer; Nyrèn added two enzymes to the synethesis reaction: (1) ATP sulfurylase, which converts pyrophosphate into ATP; (2) luciferase, which converts ATP molecules into light.
After fixing the DNA template to a solid phase, sequencing is performed by watching for light reactions after adding a single base at a time.
Pyrosequencing struggles with sequencing over homopolymers (contiguous runs of the same base), with poor performance after 4-5 identical bases.<span class="citation"><sup><a href="references.html#ref-ronaghi:1998aa" role="doc-biblioref">23</a></sup></span></p>
<p>The next significant breakthrough came in the early 2000s when Li <em>et al.</em> developed the first photocleavable fluorescent nucleotide.<span class="citation"><sup><a href="references.html#ref-li:2003aa" role="doc-biblioref">24</a></sup></span>
The novel nucleotides use a fluorescent tag to block the 3 prime hydroxyl group, which can be cleaved using a specific wavelength of light.
This allows for SBS with a “reversible termination” of synthesis after each base incorporation.
The reversible terminators, in conjunction with the development of glass-bound colony expansion,<span class="citation"><sup><a href="references.html#ref-fedurco:2006aa" role="doc-biblioref">25</a></sup></span> laid the groundwork for the Solexa system (acquired by Illumina) which currently dominates the sequencing field.<span class="citation"><sup><a href="references.html#ref-turcatti:2008aa" role="doc-biblioref">26</a></sup></span></p>
<p>Illumina sequencing works by creating clusters of identical DNA fragments bound to a glass plate (“flow cell”), then performing SBS using fluorescent reversible terminators.
To perform Illumina sequencing, specific sequencing adapters are ligated onto short DNA fragments to: (1) bind DNA fragments to the flow cell; (2) initiate amplification; (3) optionally identify the fragment source.
The flow cell contains a “lawn” of two short oligos bound to the glass surface; the fragments have homology to either the forward or reverse adapter.
The sequencing library containing the ligated forward and reverse adapters are added to the flow cell, where they hybridize to the lawn.
Once bound, polymerase is added and the bound oligo is extended using the hybridized DNA fragment as a template.
The original template is then washed away, leaving complementary sequences bound to the flow cell.
The free adapter then folds over to hybridize to its complement oligo, forming a bridge, and polymerase fills in the oligo to form a double-stranded fragment (bridge amplification).
The double-stranded fragment is denatured, leaving two single stranded fragments bound to the flow cell.
Bridge amplification is repeated until each cluster contains hundreds of the same the fragment.
The reverse fragments are then cleaved from the flow cell, and the clusters are sequenced by detecting the incorporation of fluorescent reversible terminators.
Each cluster is tracked as basepairs are incorporated, giving the final DNA sequence.</p>
</div>
<div id="processing-short-read-sequencing-data" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Processing short-read sequencing data</h3>
<p>With the advancements in sequencing chemistry, we now have the ability to sequence great amounts of DNA cheaply.
However, the massively parallel sequencing modalities only sequence small fragments of DNA (typically 50 to 500 basepairs in length) often using a “shotgun” approach – “shotgun” referring to sequencing a randomly fragmented sample rather than a known locus.
Therefore, the nature of short-read shotgun sequencing requires robust computational approaches to process and contextualize sequence data for millions of DNA fragments.</p>
<p>Here, I will give an overview of processing sequencing data for a species with an established reference genome.
Processing short-read sequencing data follows the following general steps:</p>
<ol style="list-style-type: decimal">
<li><p>pre-processing to remove artificially added sequence (sequencing adapters, sample barcodes, etc.) and create FASTA/FASTQ<span class="citation"><sup><a href="references.html#ref-pearson:1988aa" role="doc-biblioref">27</a>,<a href="references.html#ref-cock:2010aa" role="doc-biblioref">28</a></sup></span> output;</p></li>
<li><p>map individual reads to their original location in the reference genome and create Sequence Alignment Map (SAM/BAM)<span class="citation"><sup><a href="references.html#ref-li:2009aa" role="doc-biblioref">29</a></sup></span> output;</p></li>
<li><p>optional post-mapping quality control;</p></li>
<li><p>variant identification;</p></li>
<li><p>variant filtering and interpretation.</p></li>
</ol>
<p>The pre-processing step depends entirely on the sequencing chemistry and machinery uesd.
Illumina sequencers produce binary base call (BCL) files containing all of the raw base call and quality information from the sequencing run.
BCL files contain the adapter sequence (including sample barcode sequence and molecular index sequence when used in the library generation), which must be removed prior to mapping.
Due to the capacity of modern sequencing machines, most often each lane of the flow cell will contain multiple samples.
By convention, reads from each sample are separated into individual FASTQ files.
Separating reads by sample must occur prior to discarding the adapater sequence information.
Illumina currently provides the <code>bcl2fastq</code> command line tool for performing all of the requisite tasks to produce sample-specific FASTQ files with molecular index information when applicable.</p>
<p>The process of mapping individual reads (query sequences) to a reference sequence requires (1) finding the correct starting point in the reference sequence, and (2) accounting for substitutions, insertions, and deletions in the query sequence.
Smith and Waterman published the first algorithm meeting both requirements, using dynamic programming on a substitution matrix<span class="citation"><sup><a href="references.html#ref-smith:1981aa" role="doc-biblioref">30</a></sup></span> based on the inital work of Needleman and Wunsch.<span class="citation"><sup><a href="references.html#ref-needleman:1970aa" role="doc-biblioref">31</a></sup></span>
The Smith-Waterman algorithm requires user-defined scores for matches, mismatches, and gaps (insertions/deletions); the algorithm will find the best possible match with the given scoring system, but requires <span class="math inline">\(O(mn)\)</span> compute time where <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> represent the length of the reference and query sequences.</p>
<p>To reduce the complexity of the problem, Altschul <em>et al.</em> developed the basic local alignment search tool (BLAST).<span class="citation"><sup><a href="references.html#ref-altschul:1990aa" role="doc-biblioref">32</a></sup></span>
BLAST works by breaking the query sequences into a hash table of all possible <span class="math inline">\(k\)</span>-mer sub-sequences and searching the reference sequence for non-gap matches above some threshold.
For pairs of matches, BLAST extends the sequence to refine the candidate pool, and then finalizes the best candidates using the Smith-Waterman algorithm.
Many other tools take similar hash table approaches, including hashing the reference sequence rather than the query sequence.<span class="citation"><sup><a href="references.html#ref-li:2010aa" role="doc-biblioref">33</a></sup></span></p>
<p>Modern alignment algorithms have futher improved efficiency by exploiting the Burrows-Wheeler Transform (BWT).<span class="citation"><sup><a href="references.html#ref-li:2010aa" role="doc-biblioref">33</a>,<a href="references.html#ref-burrows:1994aa" role="doc-biblioref">34</a></sup></span>
The BWT creates a quickly search-able compressed representation of the reference sequence (roughly 1 gigabyte for the complete human genome), which search algorithms can hold in memory for even greater search efficiency.<span class="citation"><sup><a href="references.html#ref-lam:2008aa" role="doc-biblioref">35</a></sup></span>
The various BWT-based algorithms differ primarilly on how they handle mismatches<span class="citation"><sup><a href="references.html#ref-li:2010aa" role="doc-biblioref">33</a></sup></span>
For DNA sequencing, the Burrows Wheeler alignment tool (BWA) developed and subsequently refined by Li and Durbin in 2009 remains the <em>de facto</em> industry standard.<span class="citation"><sup><a href="references.html#ref-li:2009aa" role="doc-biblioref">29</a>,<a href="references.html#ref-li:2010ab" role="doc-biblioref">36</a></sup></span></p>
<p>Post-alignment processing prepares the mapped reads for variant calling.
Artificial duplicate reads can create bias in downstream variant calling, and deserve careful consideration.
Tw types of artificial duplicates can occur with Illumina sequencing: (1) PCR duplicates, (2) technical (optical and cluster) duplicates.
In large randomly-fragmented libraries sequenced to moderate depth, duplicate reads are much more likely to represent artificial than true duplicates.
Virtually all sequencing library preparation protocols include PCR amplification, producing artificial duplicate reads.
Using non-paterned flow cells, the image processing software my incorrectly identify large/odly shaped clusters as two separate clusters.
With patterned flow cells, occasionally the same template can “jump” into an adjascent cluster.</p>
<p>In deeply-sequenced libraries with low complexity, we are more likely to observe true read duplicates.
Without including unique molecular identifiers (UMIs) in the adapter sequence, we have no way of distinguishing true versus artificial duplicate reads.
A UMI is a short (generally 6-12 basepairs) sequence of random bases; all PCR duplicates will contain the same UMI sequence.
The exceedingly low probability of two true read duplicates having the same UMI allows properly controlling for artificial duplicates without removing true duplicates.</p>
<p>In addition to removing duplicate reads, the GATK best practices pipeline suggests adjusting the base quality scores prior to variant calling.<span class="citation"><sup><a href="references.html#ref-mckenna:2010aa" role="doc-biblioref">37</a>,<a href="references.html#ref-depristo:2011aa" role="doc-biblioref">38</a></sup></span>
GATK provides the BaseQualityScoreRecalibration tool, which uses machine learning models to correct for known systematic errors in sequencing.</p>
<p>With the final set of aligned reads, we move to identifying deviations (variants) from the reference sequence.
Numerous tools exist to perform variant calling; I will discuss the general approaches to calling the different types of variants, highlighting commonly-used algorithms.</p>
<p>Calling single base substitutions – single nucleotide variants (SNVs) – relies fundamentally on counting alleles at each locus.
At minimum, the statistical models incorporate the quality of each base call and assumptions about sequencing error rates, e.g. the samtools mpileup/bcftools call programs.<span class="citation"><sup><a href="references.html#ref-li:2011aa" role="doc-biblioref">39</a></sup></span>
GATK previously provided a similar tool, implementing a simple Bayesian genotype likelihood model,<span class="citation"><sup><a href="references.html#ref-mckenna:2010aa" role="doc-biblioref">37</a>,<a href="references.html#ref-depristo:2011aa" role="doc-biblioref">38</a>,<a href="references.html#ref-van-der-auwera:2013aa" role="doc-biblioref">40</a></sup></span> but has moved currently to a haplotype-based calling algorithm (HaplotypeCaller).<span class="citation"><sup><a href="references.html#ref-poplin:2018aa" role="doc-biblioref">41</a></sup></span>
HaplotypeCaller works by (1) identifying “active” regions containing plausible variants, (2) building possible haplotypes in the active regions using de Bruijn-like graphs, (3) assigning haplotype likelihoods to reads, and (4) calculating genotype likelihoods incorporating the estimated haplotype information.
The idea for using haplotype estimates in genotype calling originated with the freebayes algorithm.<span class="citation"><sup><a href="references.html#ref-garrison:2012aa" role="doc-biblioref">42</a></sup></span>
The above tools all use very similar approaches to call small insertions and deletions (indels).
Development continues actively in SNV/indel variant identification, and performance between algorithms predictably differs with condition.<span class="citation"><sup><a href="references.html#ref-chen:2019aa" role="doc-biblioref">43</a>,<a href="references.html#ref-xu:2018aa" role="doc-biblioref">44</a></sup></span></p>
<p>Calling larger structural variation from short-read sequencing poses greater difficulty.
SNVs and indels exist within single reads; therefore, we can view and count them directly.
We cannot directly view variation which spans lengths greater than our read (or read pair) length.
To identify larger variation, calling algorithms attempt to identify some combination of the following tw signals: (1) relative changes in sequencing depth (read depth); (2) paired read insert size and orientation (paired end mapping).</p>
<p>Read-depth methods, e.g. CNVnator,<span class="citation"><sup><a href="references.html#ref-abyzov:2011aa" role="doc-biblioref">45</a></sup></span> work by building statistical models utilizing the relative sequencing depth across the genome.
The depth bias introduced by the capture step in targeted sequencing necessitates comparing to a set of control samples, e.g. ExomeDepth,<span class="citation"><sup><a href="references.html#ref-plagnol:2012aa" role="doc-biblioref">46</a></sup></span> rather than calculating the relative depth across the genome.
Paired-end mapping methods identify sets of reads with insert sizes outside a specified range, indicating insertions or deletions, and reads with the incorrect orientation suggesting genomic rearrangements.<span class="citation"><sup><a href="references.html#ref-korbel:2007aa" role="doc-biblioref">47</a></sup></span>
The Lumpy algorithm<span class="citation"><sup><a href="references.html#ref-layer:2014aa" role="doc-biblioref">48</a></sup></span> utilizes both the read depth and paired end mapping approaches for greater detection sensitivity.
The ERDS algorithm<span class="citation"><sup><a href="references.html#ref-zhu:2012aa" role="doc-biblioref">49</a></sup></span> combines read depth information with allele ratios when possible.</p>
<p>Sequencing an individual reveals millions of variants compared to the current reference genome,<span class="citation"><sup><a href="references.html#ref-auton:2015aa" role="doc-biblioref">50</a></sup></span> often requiring filtering to identify meaning results.
Multiple public databases now exist cataloging known variants: dbSNP with SNVs and indels,<span class="citation"><sup><a href="references.html#ref-sherry:1999aa" role="doc-biblioref">51</a></sup></span> dbGaP<span class="citation"><sup><a href="references.html#ref-mailman:2007aa" role="doc-biblioref">52</a></sup></span> with variants linked to phenotypes, ClinVar<span class="citation"><sup><a href="references.html#ref-landrum:2014aa" role="doc-biblioref">53</a></sup></span> with clinical variant interpretations, ensembl<span class="citation"><sup><a href="references.html#ref-hubbard:2002aa" role="doc-biblioref">54</a>,<a href="references.html#ref-yates:2020aa" role="doc-biblioref">55</a></sup></span> which aggregates data from many sources and provides additonal analysis tools (e.g. the Variant Effect Predictor<span class="citation"><sup><a href="references.html#ref-mclaren:2016aa" role="doc-biblioref">56</a></sup></span>), and gnomAD<span class="citation"><sup><a href="references.html#ref-karczewski:2019aa" role="doc-biblioref">57</a></sup></span> with variants from &gt;100,000 human exome sequences and &gt;15,000 human genome sequences across diverse populations.
Most commonly we begin by searching the predicted variants for known pathogenic variants which explain the clinical picture.
If the search for known pathogenic variants fails, we can proceed by throwing out common variants and predicting protein-altering variants which correlate clinically.
Many tools exist for predicting variant outcome, e.g. the Ensembl Variant Effect Predictor,<span class="citation"><sup><a href="references.html#ref-mclaren:2016aa" role="doc-biblioref">56</a></sup></span> PolyPhen,<span class="citation"><sup><a href="references.html#ref-adzhubei:2013aa" role="doc-biblioref">58</a></sup></span> and JannoVar.<span class="citation"><sup><a href="references.html#ref-jager:2014aa" role="doc-biblioref">59</a></sup></span></p>
</div>
</div>
<div id="introduction-to-medical-genetics" class="section level2">
<h2><span class="header-section-number">1.4</span> Introduction to medical genetics</h2>
<p>1902 – Mendel’s theories were finally associated with a human disease by Sir Archibald Edward Garrod, who published the first findings from a study on recessive inheritance in human beings in 1902. Garrod opened the door for our understanding of genetic disorders resulting from errors in chemical pathways in the body.</p>
<p>Late 1940s – Barbara McClintock discovered the mobility of genes, ultimately challenging virtually everything that was once thought to be. Her discovery of the “jumping gene,” or the idea that genes can move on a chromosome, earned her the Nobel Prize in Physiology.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="a-novel-copy-number-variant-algorithm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DLFilerDissertation.pdf", "DLFilerDissertation.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
