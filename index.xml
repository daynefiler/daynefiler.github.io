<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DL Filer</title>
    <link>https://daynefiler.github.io/</link>
    <description>Recent content on DL Filer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 21 Jan 2022 12:05:26 -0500</lastBuildDate><atom:link href="https://daynefiler.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Setting up private GitHub R package repo with covr/codecov</title>
      <link>https://daynefiler.github.io/blog/privaterepocovr/</link>
      <pubDate>Fri, 21 Jan 2022 12:05:26 -0500</pubDate>
      
      <guid>https://daynefiler.github.io/blog/privaterepocovr/</guid>
      <description>Thanks to the usethis, testthat, and covr packages, integrating testing and code coverage into your R package is easier than ever. After installing the packages, the usethis package will setup the infrastructure for you:
library(usethis) library(testthat) library(covr) usethis::use_testthat() usethis::use_coverage() usethis::use_github_action(&amp;quot;test-coverage&amp;quot;) You can then start writing tests and monitor your coverage. If you&amp;rsquo;re using this on a private repository, you need to take a couple extra steps, which is where I got hung up.</description>
    </item>
    
    <item>
      <title>SMFM Pregnancy Meeting 2020</title>
      <link>https://daynefiler.github.io/blog/smfm2020/</link>
      <pubDate>Wed, 22 Jan 2020 10:41:12 -0500</pubDate>
      
      <guid>https://daynefiler.github.io/blog/smfm2020/</guid>
      <description>Hi, thank you for your interest in our prenatal genotyping work. You can find our poster from the SMFM Annual Pregnancy Meeting HERE. Please feel free to contact me regarding the work or potential collaborations. I am also happy to grab a coffee at the meeting if you would like to speak in person.
  Objective: Congenital abnormalities affect 3-4% of pregnancies and cause 20-30% of neonatal deaths worldwide. Non-invasive prenatal screening (NIPS) leverages the existence of cell-free fetal DNA (cffDNA) with next-generation sequencing to predict fetal presence of large chromosomal abnormalities and, recently, de novo or paternally-inherited dominant SNPs.</description>
    </item>
    
    <item>
      <title>Log-Sum-Exp trick for getting posterior probabilities from small likelihoods.</title>
      <link>https://daynefiler.github.io/blog/log-sum-exp/</link>
      <pubDate>Thu, 10 Oct 2019 11:29:37 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/blog/log-sum-exp/</guid>
      <description>To formulate the problem, consider calculating the posterior probability given a series of weighted likelihoods. Let  $$ x_i $$  be the likelihood for observation *i*. We wish to calculate the posterior probability as:  $$ p_i = \frac{x_i}{\sum_j x_j} $$  As Robert Eisele very nicely discusses in [his blog post](https://www.xarg.org/2016/06/the-log-sum-exp-trick-in-machine-learning/), we can run into underflow issues. Suppose you have the following vector of logged likelihoods. ```r x \begin{align} \text{log}\left(\frac{x_i}{\sum_j x_j}\right) &amp;= \text{log}x_i - \text{log}\sum_j x_j \\ &amp;= \text{log}x_i - \text{log}\sum_j e^{\text{log}x_j} \\ \end{align}  Given the proof from Robert Eisele, we know:  $$ \text{log}\sum_i e^{y_i} = \text{log}\sum_i e^{y_i - a} + a $$  for arbitrary *a*.</description>
    </item>
    
    <item>
      <title>Downloading gnomAD</title>
      <link>https://daynefiler.github.io/blog/downloadgnomad/</link>
      <pubDate>Thu, 20 Jun 2019 14:30:16 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/blog/downloadgnomad/</guid>
      <description>Here is a concise guide to downloading gnomAD using gsutil. I am typically working on a server, and (begrudgingly) use conda to manage software. The only real trick here is getting the conda environment setup &amp;ndash; I could have easily called this &amp;ldquo;Using gsutil with conda.&amp;rdquo; &amp;ndash; the actual gsutil utility is pretty easy to use. gsutil, needed for accessing the gnomAD data, is buried within the &amp;lsquo;google-cloud-sdk&amp;rsquo; conda package, not to be confused with the numerous other &amp;lsquo;google-cloud-&amp;rsquo; conda packages.</description>
    </item>
    
    <item>
      <title>Accessing NIH FTP</title>
      <link>https://daynefiler.github.io/blog/accessingnihftp/</link>
      <pubDate>Mon, 11 Feb 2019 11:11:05 -0500</pubDate>
      
      <guid>https://daynefiler.github.io/blog/accessingnihftp/</guid>
      <description>This should be trivial, and it is with the right instructions. Unfortunately, those are not listed in the disclaimer given when connecting to the NIH FTP site. The NIH gives the instructions here. The NIH FTP offers a standard anonymous connection. Anonymous connections use &amp;ldquo;anonymous&amp;rdquo; as the user and the connecting user&amp;rsquo;s email as the password. Briefly, follow the command in a Unix terminal:
ftp ftp.ncbi.nih.gov You should receive a prompt that looks like &amp;ldquo;Name (ftp.</description>
    </item>
    
    <item>
      <title>G-indexing in VCF files</title>
      <link>https://daynefiler.github.io/blog/gindexing/</link>
      <pubDate>Mon, 30 Jul 2018 13:09:45 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/blog/gindexing/</guid>
      <description>The gnomAD VCF files give information about the observed genotype counts, eg &amp;ldquo;GC_EAS&amp;rdquo; gives the genotype counts for individuals of East Asian decent as a comma-separated string. The order of the counts is determined by genotype-indexing. The above link gives an excellent discussion of getting the genotype index for the general case, regardless of ploidy number. Below is a brief discussion of haploid and diploid indices.
Genotype-indexing works by first indexing the reference and alternative alleles, starting with the reference allele at 0.</description>
    </item>
    
    <item>
      <title>Consulting</title>
      <link>https://daynefiler.github.io/consulting/</link>
      <pubDate>Mon, 23 Jul 2018 17:01:43 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/consulting/</guid>
      <description>I have a strong computational &amp;amp; statistical toolkit for developing robust and reproducible analytics. While working with the US EPA National Center for Computational Toxicology I completely overhauled the analytic framework for storing and processing high-throughput chemical screening data, resulting in the tcpl R package. tcpl is efficient, scalable, user-friendly, and reproducible with complete transparency. The platform is now used across government, industry, and academia as the leading tool for processing and storing high-throughput and high-content chemical screening.</description>
    </item>
    
  </channel>
</rss>
