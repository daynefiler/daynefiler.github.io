<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dayne L Filer</title>
    <link>https://daynefiler.github.io/</link>
    <description>Recent content on Dayne L Filer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Thu, 10 Oct 2019 11:29:37 -0400</lastBuildDate>
    
	<atom:link href="https://daynefiler.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Log-Sum-Exp trick for getting posterior probabilities from small likelihoods.</title>
      <link>https://daynefiler.github.io/blog/log-sum-exp/</link>
      <pubDate>Thu, 10 Oct 2019 11:29:37 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/blog/log-sum-exp/</guid>
      <description>To formulate the problem, consider calculating the posterior probability given a series of weighted likelihoods. Let
 $$ x_i $$  be the likelihood for observation i. We wish to calculate the posterior probability as:
 $$ p_i = \frac{x_i}{\sum_j x_j} $$  As Robert Eisele very nicely discusses in his blog post, we can run into underflow issues. Suppose you have the following vector of logged likelihoods.
x &amp;lt;- c(-9000, -3000, -1000) exp(x)/sum(exp(x)) # [1] NaN NaN NaN  As we can see, all the values will be zero.</description>
    </item>
    
    <item>
      <title>Downloading gnomAD</title>
      <link>https://daynefiler.github.io/blog/downloadgnomad/</link>
      <pubDate>Thu, 20 Jun 2019 14:30:16 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/blog/downloadgnomad/</guid>
      <description>Here is a concise guide to downloading gnomAD using gsutil. I am typically working on a server, and (begrudgingly) use conda to manage software. The only real trick here is getting the conda environment setup &amp;ndash; I could have easily called this &amp;ldquo;Using gsutil with conda.&amp;rdquo; &amp;ndash; the actual gsutil utility is pretty easy to use. gsutil, needed for accessing the gnomAD data, is buried within the &amp;lsquo;google-cloud-sdk&amp;rsquo; conda package, not to be confused with the numerous other &amp;lsquo;google-cloud-&amp;rsquo; conda packages.</description>
    </item>
    
    <item>
      <title>Accessing NIH FTP</title>
      <link>https://daynefiler.github.io/blog/accessingnihftp/</link>
      <pubDate>Mon, 11 Feb 2019 11:11:05 -0500</pubDate>
      
      <guid>https://daynefiler.github.io/blog/accessingnihftp/</guid>
      <description>This should be trivial, and it is with the right instructions. Unfortunately, those are not listed in the disclaimer given when connecting to the NIH FTP site. The NIH gives the instructions here. The NIH FTP offers a standard anonymous connection. Anonymous connections use &amp;ldquo;anonymous&amp;rdquo; as the user and the connecting user&amp;rsquo;s email as the password. Briefly, follow the command in a Unix terminal:
ftp ftp.ncbi.nih.gov  You should receive a prompt that looks like &amp;ldquo;Name (ftp.</description>
    </item>
    
    <item>
      <title>G-indexing in VCF files</title>
      <link>https://daynefiler.github.io/blog/gindexing/</link>
      <pubDate>Mon, 30 Jul 2018 13:09:45 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/blog/gindexing/</guid>
      <description>The gnomAD VCF files give information about the observed genotype counts, eg &amp;ldquo;GC_EAS&amp;rdquo; gives the genotype counts for individuals of East Asian decent as a comma-separated string. The order of the counts is determined by genotype-indexing. The above link gives an excellent discussion of getting the genotype index for the general case, regardless of ploidy number. Below is a brief discussion of haploid and diploid indices.
Genotype-indexing works by first indexing the reference and alternative alleles, starting with the reference allele at 0.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://daynefiler.github.io/about/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://daynefiler.github.io/about/</guid>
      <description>I grew up in Boise, Idaho. After finishing college at The College of Idaho I moved to Durham, North Carolina for a research fellowship with the US EPA. In 2015 my wife and I decided to stay in Durham for the long-haul as I started at UNC in the MD/PhD program. I am currently working on my PhD in Bioinformatics and Computational Biology under the mentorship of Kirk Wilhelmsen at the Renaissance Computing Institute.</description>
    </item>
    
    <item>
      <title>Consulting</title>
      <link>https://daynefiler.github.io/consulting/</link>
      <pubDate>Mon, 23 Jul 2018 17:01:43 -0400</pubDate>
      
      <guid>https://daynefiler.github.io/consulting/</guid>
      <description>Over the last six years I have developed a strong computational toolkit for developing robust and reproducible analytics. While working with the US EPA National Center for Computational Toxicology I completely overhauled the analytic framework for storing and processing high-throughput chemical screening data, resulting in the tcpl R package. tcpl is efficient, scalable, user-friendly, and reproducible with complete transparency. The platform is now used across government, industry, and academia as the leading tool for processing and storing high-throughput and high-content chemical screening.</description>
    </item>
    
  </channel>
</rss>